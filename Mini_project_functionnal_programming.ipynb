{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMblpqJ7FLxIDeUAKyb40vG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyaminedb1/Restaurant-item-analyse-/blob/main/Mini_project_functionnal_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Q_GDaeHdIi",
        "outputId": "3e422ced-3155-404b-de4d-f2afa397dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9538 entries, 0 to 9537\n",
            "Data columns (total 17 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Age                 9538 non-null   int64  \n",
            " 1   Pregnancies         9538 non-null   int64  \n",
            " 2   BMI                 9538 non-null   float64\n",
            " 3   Glucose             9538 non-null   float64\n",
            " 4   BloodPressure       9538 non-null   float64\n",
            " 5   HbA1c               9538 non-null   float64\n",
            " 6   LDL                 9538 non-null   float64\n",
            " 7   HDL                 9538 non-null   float64\n",
            " 8   Triglycerides       9538 non-null   float64\n",
            " 9   WaistCircumference  9538 non-null   float64\n",
            " 10  HipCircumference    9538 non-null   float64\n",
            " 11  WHR                 9538 non-null   float64\n",
            " 12  FamilyHistory       9538 non-null   int64  \n",
            " 13  DietType            9538 non-null   int64  \n",
            " 14  Hypertension        9538 non-null   int64  \n",
            " 15  MedicationUse       9538 non-null   int64  \n",
            " 16  Outcome             9538 non-null   int64  \n",
            "dtypes: float64(10), int64(7)\n",
            "memory usage: 1.2 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "    Age  Pregnancies    BMI  Glucose  BloodPressure  HbA1c    LDL   HDL  \\\n",
              " 0   69            5  28.39    130.1           77.0    5.4  130.4  44.0   \n",
              " 1   32            1  26.49    116.5           72.0    4.5   87.4  54.2   \n",
              " 2   89           13  25.34    101.0           82.0    4.9  112.5  56.8   \n",
              " 3   78           13  29.91    146.0          104.0    5.7   50.7  39.1   \n",
              " 4   38            8  24.56    103.2           74.0    4.7  102.5  29.1   \n",
              " \n",
              "    Triglycerides  WaistCircumference  HipCircumference   WHR  FamilyHistory  \\\n",
              " 0           50.0                90.5             107.9  0.84              0   \n",
              " 1          129.9               113.3              81.4  1.39              0   \n",
              " 2          177.6                84.7             107.2  0.79              0   \n",
              " 3          117.0               108.9             110.0  0.99              0   \n",
              " 4          145.9                84.1              92.8  0.91              0   \n",
              " \n",
              "    DietType  Hypertension  MedicationUse  Outcome  \n",
              " 0         0             0              1        0  \n",
              " 1         0             0              0        0  \n",
              " 2         0             0              1        0  \n",
              " 3         0             0              1        1  \n",
              " 4         1             0              0        0  ,\n",
              " Age                   0\n",
              " Pregnancies           0\n",
              " BMI                   0\n",
              " Glucose               0\n",
              " BloodPressure         0\n",
              " HbA1c                 0\n",
              " LDL                   0\n",
              " HDL                   0\n",
              " Triglycerides         0\n",
              " WaistCircumference    0\n",
              " HipCircumference      0\n",
              " WHR                   0\n",
              " FamilyHistory         0\n",
              " DietType              0\n",
              " Hypertension          0\n",
              " MedicationUse         0\n",
              " Outcome               0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/diabetes_dataset.csv\")\n",
        "\n",
        "# Display basic information about the dataset\n",
        "df_info = df.info()\n",
        "df_head = df.head()\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display dataset overview\n",
        "df_info, df_head, missing_values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "features = [\"Age\", \"BMI\", \"Glucose\", \"BloodPressure\", \"HbA1c\", \"LDL\", \"HDL\", \"Triglycerides\", \"WHR\"]\n",
        "target = \"Outcome\"  # Using Outcome as a proxy for fitness risk\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df[features])\n",
        "y = df[target].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to JAX tensors\n",
        "X_train = jnp.array(X_train)\n",
        "y_train = jnp.array(y_train)\n",
        "X_test = jnp.array(X_test)\n",
        "y_test = jnp.array(y_test)\n",
        "\n",
        "\n",
        "# Define multiple basis functions\n",
        "def polynomial_basis(x, degree=3):\n",
        "    return jnp.concatenate([x**i for i in range(1, degree + 1)], axis=1)\n",
        "\n",
        "def radial_basis(x, centers, gamma=1.0):\n",
        "    # centers should have the same number of features as x\n",
        "    centers = centers.reshape(1, -1, x.shape[1])  # Ensure proper broadcasting\n",
        "    return jnp.exp(-gamma * jnp.linalg.norm(x[:, None, :] - centers, axis=-1) ** 2)\n",
        "\n",
        "# Apply basis transformations\n",
        "X_train_poly = polynomial_basis(X_train)\n",
        "X_test_poly = polynomial_basis(X_test)\n",
        "\n",
        "# Generate centers with the correct number of features\n",
        "num_centers = 10\n",
        "centers = jnp.linspace(-2, 2, num=num_centers).reshape(num_centers, 1)\n",
        "# Tile centers to match the number of features\n",
        "centers = jnp.tile(centers, (1, X_train.shape[1]))\n",
        "\n",
        "X_train_rbf = radial_basis(X_train, centers)\n",
        "X_test_rbf = radial_basis(X_test, centers)\n",
        "\n",
        "# Initialize model parameters\n",
        "key = jax.random.PRNGKey(0)\n",
        "w = jax.random.normal(key, (X_train_poly.shape[1],))\n",
        "b = jnp.array(0.0)\n",
        "\n",
        "# Define function approximation model\n",
        "def model(params, x):\n",
        "    w, b = params\n",
        "    return jnp.dot(x, w) + b\n",
        "\n",
        "# Loss function (Mean Squared Error)\n",
        "def loss_fn(params, x, y):\n",
        "    predictions = model(params, x)\n",
        "    return jnp.mean((predictions - y) ** 2)\n",
        "\n",
        "# Define training step\n",
        "def train_step(params, opt_state, x, y, optimizer):\n",
        "    loss, grads = jax.value_and_grad(loss_fn)(params, x, y)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    return params, opt_state, loss\n",
        "\n",
        "# Compare multiple optimization algorithms with learning rate scheduling\n",
        "schedule = optax.exponential_decay(init_value=0.01, transition_steps=100, decay_rate=0.95)\n",
        "grad_clip = 1.0  # Gradient clipping threshold\n",
        "\n",
        "optimizers = {\n",
        "    \"Adam\": optax.chain(optax.clip_by_global_norm(grad_clip), optax.adam(schedule)),\n",
        "    \"SGD\": optax.chain(optax.clip_by_global_norm(grad_clip), optax.sgd(schedule)),\n",
        "    \"RMSProp\": optax.chain(optax.clip_by_global_norm(grad_clip), optax.rmsprop(schedule))\n",
        "}\n",
        "\n",
        "# Train and evaluate different optimizers\n",
        "results = {}\n",
        "for name, optimizer in optimizers.items():\n",
        "    opt_state = optimizer.init((w, b))\n",
        "    params = (w, b)\n",
        "\n",
        "    print(f\"\\nTraining with {name}...\")\n",
        "    for epoch in range(500):\n",
        "        params, opt_state, loss = train_step(params, opt_state, X_train_poly, y_train, optimizer)\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"Optimizer: {name}, Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "    # Test performance\n",
        "    y_pred = model(params, X_test_poly)\n",
        "    mse = jnp.mean((y_pred - y_test) ** 2)\n",
        "    results[name] = mse\n",
        "    print(f\"Final Test MSE with {name}: {mse:.4f}\")\n",
        "\n",
        "# Print results\n",
        "print(\"\\nOptimizer Comparison:\")\n",
        "for opt, mse in results.items():\n",
        "    print(f\"{opt}: MSE = {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mneqqf6WH2MO",
        "outputId": "e21ba89a-cac7-44bc-fddd-5dcd83fbca23"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Adam...\n",
            "Optimizer: Adam, Epoch 0, Loss: 238.3786\n",
            "Optimizer: Adam, Epoch 50, Loss: 65.5503\n",
            "Optimizer: Adam, Epoch 100, Loss: 11.0547\n",
            "Optimizer: Adam, Epoch 150, Loss: 1.1261\n",
            "Optimizer: Adam, Epoch 200, Loss: 0.2630\n",
            "Optimizer: Adam, Epoch 250, Loss: 0.2155\n",
            "Optimizer: Adam, Epoch 300, Loss: 0.2095\n",
            "Optimizer: Adam, Epoch 350, Loss: 0.2087\n",
            "Optimizer: Adam, Epoch 400, Loss: 0.2087\n",
            "Optimizer: Adam, Epoch 450, Loss: 0.2087\n",
            "Final Test MSE with Adam: 0.2106\n",
            "\n",
            "Training with SGD...\n",
            "Optimizer: SGD, Epoch 0, Loss: 238.3786\n",
            "Optimizer: SGD, Epoch 50, Loss: 169.8994\n",
            "Optimizer: SGD, Epoch 100, Loss: 116.2994\n",
            "Optimizer: SGD, Epoch 150, Loss: 75.9564\n",
            "Optimizer: SGD, Epoch 200, Loss: 47.1178\n",
            "Optimizer: SGD, Epoch 250, Loss: 27.8169\n",
            "Optimizer: SGD, Epoch 300, Loss: 15.8845\n",
            "Optimizer: SGD, Epoch 350, Loss: 9.2381\n",
            "Optimizer: SGD, Epoch 400, Loss: 6.0302\n",
            "Optimizer: SGD, Epoch 450, Loss: 4.2906\n",
            "Final Test MSE with SGD: 3.1091\n",
            "\n",
            "Training with RMSProp...\n",
            "Optimizer: RMSProp, Epoch 0, Loss: 238.3786\n",
            "Optimizer: RMSProp, Epoch 50, Loss: 49.7154\n",
            "Optimizer: RMSProp, Epoch 100, Loss: 7.5773\n",
            "Optimizer: RMSProp, Epoch 150, Loss: 1.0373\n",
            "Optimizer: RMSProp, Epoch 200, Loss: 0.4343\n",
            "Optimizer: RMSProp, Epoch 250, Loss: 0.2654\n",
            "Optimizer: RMSProp, Epoch 300, Loss: 0.2253\n",
            "Optimizer: RMSProp, Epoch 350, Loss: 0.2183\n",
            "Optimizer: RMSProp, Epoch 400, Loss: 0.2172\n",
            "Optimizer: RMSProp, Epoch 450, Loss: 0.2167\n",
            "Final Test MSE with RMSProp: 0.2216\n",
            "\n",
            "Optimizer Comparison:\n",
            "Adam: MSE = 0.2106\n",
            "SGD: MSE = 3.1091\n",
            "RMSProp: MSE = 0.2216\n"
          ]
        }
      ]
    }
  ]
}